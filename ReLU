ReLU is Rectified Linear Unit
Output = Input

Types
- Sigmoid 
- Tanh

Activation Function
How to implement
Advantages of ReLU

Alternatives to ReLU

